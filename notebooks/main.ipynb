{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_px = 64\n",
    "learning_rate = 0.005\n",
    "num_iterations = 2000\n",
    "print_cost = True\n",
    "limit = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, num_px=64, limit=100000000):\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    images = []\n",
    "    index = 0\n",
    "    for file in files:\n",
    "        if index > limit:\n",
    "            break\n",
    "        image = io.imread(os.path.join(path, file))\n",
    "        images.append(resize(image, (num_px, num_px), mode='constant'))\n",
    "        index += 1\n",
    "\n",
    "    return np.array(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_images = load_images('../data/images/target', num_px, limit=limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_images = load_images('../data/images/others', num_px, limit=limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../data/target_images_vec.npy', target_images)\n",
    "# np.save('../data/other_images_vec.npy', other_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_images_flatten = target_images.reshape(target_images.shape[0], -1)\n",
    "other_images_flatten = other_images.reshape(other_images.shape[0], -1)\n",
    "\n",
    "target_values = np.ones((len(target_images), 1))\n",
    "other_values = np.zeros((len(other_images), 1))\n",
    "\n",
    "X = np.concatenate((target_images_flatten, other_images_flatten), axis=0)\n",
    "y = np.concatenate((target_values, other_values), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset into train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "X_train = X_train.T\n",
    "y_train = y_train.T\n",
    "X_test = X_test.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "    s = (1 / ( 1 + np.exp(-z)))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    w = np.zeros((dim, 1))\n",
    "    b = 0\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T,X)+b)                # compute activation\n",
    "    cost = (-1/m) * np.sum((Y * np.log(A)) + ((1 - Y) * np.log(1 - A)))     # compute cost\n",
    "    \n",
    "    #compute gradients\n",
    "    dw = np.dot(X,(A-Y).T) / m\n",
    "    db = np.sum(A-Y) / m\n",
    "\n",
    "    cost = np.squeeze(cost)\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        #update weights and b\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "    \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 100 training iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        if A[0,i] > 0.5:\n",
    "            Y_prediction[0,i] = 1\n",
    "        else:\n",
    "            Y_prediction[0,i] = 0\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x shape: (12288, 641)\n",
      "train_set_y shape: (1, 641)\n",
      "test_set_x shape: (12288, 161)\n",
      "test_set_y shape: (1, 161)\n",
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.225528\n",
      "Cost after iteration 200: 0.198166\n",
      "Cost after iteration 300: 0.181116\n",
      "Cost after iteration 400: 0.168456\n",
      "Cost after iteration 500: 0.158212\n",
      "Cost after iteration 600: 0.149525\n",
      "Cost after iteration 700: 0.141950\n",
      "Cost after iteration 800: 0.135219\n",
      "Cost after iteration 900: 0.129159\n",
      "Cost after iteration 1000: 0.123649\n",
      "Cost after iteration 1100: 0.118600\n",
      "Cost after iteration 1200: 0.113945\n",
      "Cost after iteration 1300: 0.109631\n",
      "Cost after iteration 1400: 0.105617\n",
      "Cost after iteration 1500: 0.101870\n",
      "Cost after iteration 1600: 0.098361\n",
      "Cost after iteration 1700: 0.095067\n",
      "Cost after iteration 1800: 0.091968\n",
      "Cost after iteration 1900: 0.089048\n",
      "test accuracy: 91.92546583850931 %\n",
      "train accuracy: 98.12792511700468 %\n"
     ]
    }
   ],
   "source": [
    "print (\"train_set_x shape: \" + str(X_train.shape))\n",
    "print (\"train_set_y shape: \" + str(y_train.shape))\n",
    "print (\"test_set_x shape: \" + str(X_test.shape))\n",
    "print (\"test_set_y shape: \" + str(y_test.shape))\n",
    "\n",
    "w, b = initialize_with_zeros(len(X_train))\n",
    "parameters, grads, costs = optimize(w, b, X_train, y_train, num_iterations, learning_rate, print_cost)\n",
    "\n",
    "w = parameters[\"w\"]\n",
    "b = parameters[\"b\"]\n",
    "\n",
    "y_prediction_test = predict(w, b, X_test)\n",
    "y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  0.99607843, ...,  0.37916667,\n",
       "         1.        ,  0.16369485],\n",
       "       [ 1.        ,  1.        ,  1.        , ...,  0.31878064,\n",
       "         1.        ,  0.16761642],\n",
       "       [ 1.        ,  1.        ,  1.        , ...,  0.22858456,\n",
       "         1.        ,  0.14800858],\n",
       "       ..., \n",
       "       [ 1.        ,  1.        ,  1.        , ...,  0.08235294,\n",
       "         1.        ,  0.60101103],\n",
       "       [ 1.        ,  1.        ,  1.        , ...,  0.09803922,\n",
       "         1.        ,  0.56963848],\n",
       "       [ 1.        ,  1.        ,  1.        , ...,  0.10980392,\n",
       "         1.        ,  0.48728554]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
